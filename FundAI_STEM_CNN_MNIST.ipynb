{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FundAI-STEM-CNN-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgader/AI-For-STEM/blob/master/FundAI_STEM_CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# Fundamentals of AI for STEM HW 4\n",
        "# Interpreting Features Extracted by Trained CNN Filters\n",
        "\n",
        "<h1> <center> Instructions </center> </h1>\n",
        "\n",
        "### In this homework, you will train a CNN using Tensor Flow and try to interpret the features extracted by the Convolution Filters.  There are 32 filters in the CNN.  You should try to interpret the first 12 filters.  The interpretation of each Filter can be one of the following four categories:\n",
        "\n",
        "1. Edge detector.  If it is an Edge, the estimate the orientation between 0 and 180 degrees.(0 and 180 degrees are horizontal)\n",
        "2. Point detector. (Junction, Corner, Isolated, points, etc.)\n",
        "3. Smoothing.\n",
        "4. Cannot Interpret\n",
        "\n",
        "+ The dataset is the famous (or infamous) MNIST handwritten digit data which is useful because it is easy to interpret.\n",
        "__________________________________________________________________\n",
        "### To start the homework, execute the cells by putting your cursor in each code cell (they are shaded with gray) sequentially and type shift - enter simultaneously. \n",
        "\n",
        "+ Each cell will show a number inside brackets, e.g. [1], when it is finished executing.\n",
        "\n",
        "+ When you execute the first cell, Colab may tell you that you do not have access to their GPUs.  In that case, select the non-GPU option.\n",
        "\n",
        "+ Once you have executed cell [8], the CNN is ready to be trained.  The training code is clearly indicated in the cell after cell [8].  \n",
        "+ Execute the cell for training; it may take a couple of minutes.  It took a couple minutes on my Macbook Pro.\n",
        "+ The training code will print progress after every Epoch.  It is currently set to 3 Epochs.  The performance on the Test Data should be around 98%.\n",
        "+ Once the CNN is trained, the training code will be in cell [9].\n",
        "+ Execute the next 2 cells and you should see a dispaly of all the filters.\n",
        "+ Execute the next cell and you should see a printout of the numbers in each filter\n",
        "+ Execute the next 2 cells and you can look at the Feature Map corresponding to a specific filter and input image.  \n",
        "  + You can select the image from the MNIST test set by setting ImNum = N, where N is between 0 and 9999.\n",
        "  + You can select the filter by setting FilterNum = M, where M is between \n",
        "  + This may be the most helpful\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYeNom6a80H"
      },
      "source": [
        "# This notebook is a combination and adaptation of the\n",
        "\n",
        "## TensorFlow 2 quickstart for experts Google Colab notebook\n",
        "\n",
        "and\n",
        "\n",
        "## The suggestions given by Jason Brownlee at the URL:\n",
        "\n",
        "https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SIJAxY1a1iM"
      },
      "source": [
        "_____\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/quickstart/advanced\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOsVdx6GGHmU"
      },
      "source": [
        "Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFjR2ScT_Xwp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7DDTiZGRTo"
      },
      "source": [
        "Import TensorFlow into your program:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model, models"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFRS6K07jJs"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Evqx0S22r_"
      },
      "source": [
        "Use `tf.data` to batch and shuffle the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iu_quO024c2"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "  def ConvOut(self,x):\n",
        "    x = self.conv1(x)\n",
        "    return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "Choose an optimizer and loss function for training: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0MqHFb4F_qn"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Use `tf.GradientTape` to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZACiVqA8KQV"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "Test the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIKdEzHAJGt7"
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-2pkctU_Ci7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd84876-bc9a-4584-9974-dcc544542e5a"
      },
      "source": [
        "#############################################################\n",
        "### THIS CELL TRAINS A CNN WITH 32 FILTERS                ###\n",
        "### IN THE FIRST, AND ONLY, CONVOLUTION LAYER             ###\n",
        "#############################################################\n",
        "EPOCHS = 3 #5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.13267728686332703, Accuracy: 96.0683364868164, Test Loss: 0.06888056546449661, Test Accuracy: 97.68999481201172\n",
            "Epoch 2, Loss: 0.040091268718242645, Accuracy: 98.77166748046875, Test Loss: 0.05173422396183014, Test Accuracy: 98.18999481201172\n",
            "Epoch 3, Loss: 0.020934997126460075, Accuracy: 99.33500671386719, Test Loss: 0.047581449151039124, Test Accuracy: 98.40999603271484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DgJugxfTPQW"
      },
      "source": [
        "#####################################################################################\n",
        "### THIS CELL IMPORTS matplotlib PACKAGES USEFUL FOR DISPLAYS                     ###\n",
        "### AND STORES THE CONVOLUTION FILTERS AND BIASES IN VARIABLES filters AND biases ###\n",
        "#####################################################################################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "filters, biases = model.layers[0].get_weights()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvCZlJR-VSGI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "6fb573c8-d75a-4625-8fca-b63179d82cef"
      },
      "source": [
        "#####################################################################################\n",
        "### THIS CELL DISPLAYS ALL 32 CONVOLUTION FILTERS AS IMAGES                       ###\n",
        "### AND STORES THE CONVOLUTION FILTERS AND BIASES IN VARIABLES filters AND biases ###\n",
        "#####################################################################################\n",
        "\n",
        "print('            Here are pictures of the convolution filters', end='\\n\\n')\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = abs(filters.min()), abs(filters.max())\n",
        "if(f_max > 0):\n",
        "  filters = filters/f_max\n",
        "\n",
        "# set up figure for display\n",
        "Fig = plt.figure(figsize=(12.2, 9.6))\n",
        "Fig.set_size_inches(7.5,10.5)\n",
        "Fig.set_figheight(10)\n",
        "Fig.set_figwidth(10)\n",
        "spec = gridspec.GridSpec(ncols=4, nrows=3,\n",
        "                         width_ratios=[2, 2,2,2], wspace=0.5,\n",
        "                         hspace=0.1, height_ratios=[1,1,1])\n",
        "\n",
        "# display the 32 filters as an 8 x 4 array or\n",
        "# Just display the first 12 to reduce time to interpret\n",
        "NToIntrpt = 12\n",
        "for i in range(NToIntrpt):\n",
        "  # get the filter\n",
        "  f = filters[:, :, 0, i]\n",
        "  # specify subplot and turn of axis\n",
        "  \n",
        "  ax = Fig.add_subplot(spec[i])\n",
        "  ax.imshow(f, cmap='jet')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Here are pictures of the convolution filters\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrgH3pF-hcSs",
        "outputId": "5863442c-cb3d-44e2-a149-25acf869d0ed"
      },
      "source": [
        "#####################################################################################\n",
        "### THIS CELL PRINTS ALL 32 CONVOLUTION FILTERS                                   ###\n",
        "#####################################################################################\n",
        "print('       Here are the values of the convolution filters x 100 and rounded', end='\\n\\n')\n",
        "for MIdx in range(4):\n",
        "  for dIdx in range(5*3+3):\n",
        "    print('-', end='')\n",
        "  print('%s' %('  '),end='')\n",
        "print('\\n')\n",
        "\n",
        "NFiltRows = 3\n",
        "NFiltCols = 4\n",
        "FiltSz    = 3\n",
        "RndFilters = np.round(100*filters)\n",
        "fnum = 0;\n",
        "for srow in range(NFiltRows):\n",
        "    for frow in range(FiltSz):\n",
        "      for scol in range(NFiltCols):\n",
        "        MaskIdx = srow*4 + scol\n",
        "        #print(srow,frow,scol,MaskIdx)\n",
        "        Mask    = np.round(RndFilters[:,:,0,MaskIdx])      \n",
        "        print('%5d %5d %5d' %(Mask[frow,0], Mask[frow,1], Mask[frow,2]),end=' | ')\n",
        "      print('\\n')\n",
        "    for MIdx in range(4):\n",
        "      for dIdx in range(5*3+3):\n",
        "        print('-', end='')\n",
        "      print('%s' %('  '),end='')\n",
        "    print('\\n')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Here are the values of the convolution filters x 100 and rounded\n",
            "\n",
            "------------------  ------------------  ------------------  ------------------  \n",
            "\n",
            "   59   -16   -62 |    16    15   -27 |    10   -21    39 |    51    10   -77 | \n",
            "\n",
            "   42   -12   -49 |     7   -50    -7 |    29    -5    -7 |    42   -37   -55 | \n",
            "\n",
            "   59    -3   -12 |     8    22    35 |     2   -18   -14 |     3   -49    11 | \n",
            "\n",
            "------------------  ------------------  ------------------  ------------------  \n",
            "\n",
            "    3    51   -21 |   -17    35     6 |    61    37  -107 |   -32  -112   -63 | \n",
            "\n",
            "  -21   -17    24 |   -21    10    31 |    46  -179    14 |    45     0  -122 | \n",
            "\n",
            "  -31     8    26 |   -63   -52    37 |  -125    18   100 |    87    63   -39 | \n",
            "\n",
            "------------------  ------------------  ------------------  ------------------  \n",
            "\n",
            "  -82    39    20 |   -87   -50   -27 |    56    43   -76 |   -28    12    33 | \n",
            "\n",
            "  -72   -14    39 |   -65    31   -22 |    15     3   -97 |    10    -7    -5 | \n",
            "\n",
            "  -72     6    52 |    31    -5    39 |   -20   -71   -62 |    34   -10    10 | \n",
            "\n",
            "------------------  ------------------  ------------------  ------------------  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTwj7LstaMGT"
      },
      "source": [
        "#################################################\n",
        "### THIS CELL AND THE NEXT PRINT/DISPLAY      ###\n",
        "###  THE FILTER, IMAGE AND FEATURE MAP FOR    ###\n",
        "### A SPECIFIC TEST IMAGE AND FILTER          ###\n",
        "###                                           ###\n",
        "### JUST EXECUTE THIS CELL ONCE.              ###\n",
        "### IT RUNS THE TEST SET THROUGH THE MODEL    ###\n",
        "#################################################\n",
        "predictions = model(x_test, training=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vgVyZbmlwcjJ",
        "outputId": "6665b567-07e0-4518-96eb-af4fb9fe7680"
      },
      "source": [
        "#################################################\n",
        "###                                           ###\n",
        "### THIS CELL PRINTS AND DISPLAYS             ###\n",
        "### THE FILTER, IMAGE AND FEATURE MAP FOR     ###\n",
        "### A SPECIFIC TEST IMAGE AND FILTER          ###\n",
        "### THAT YOU PICK                             ###\n",
        "###                                           ###\n",
        "#################################################\n",
        "\n",
        "### SET THE FILTER AND IMAGE NUMBER PARAMETERS ###\n",
        "FilterNum = 11 #MUST BE BETWEEN 0 AND 31\n",
        "ImNum     = 6025 #MUST BE BETWEEN 0 AND 9999\n",
        "\n",
        "### GET THE ORIGINAL IMAGE.                          ###\n",
        "### Im IS FOR DISPLAY.                               ###\n",
        "### ImTf IS IN CORRECT FORMAT TO ACCESS FEATURE MAPS ###\n",
        "ImTf  = x_test[ImNum]\n",
        "Im    = np.reshape(ImTf, [28,28])\n",
        "ImTf  = ImTf[tf.newaxis,...].astype(\"float32\")\n",
        "\n",
        "### GET THE FEATURE MAP AND FILTER ###\n",
        "FMaps = model.conv1(ImTf)\n",
        "FMap  = FMaps[0,:,:,FilterNum]\n",
        "filt  = RndFilters[:,:,0,FilterNum]\n",
        "\n",
        "### PRINT THE FILTER ###\n",
        "print('Filter number %d is\\n' %FilterNum)\n",
        "for r in range(3):\n",
        "  for c in range(3):\n",
        "    print('%4d ' %filt[r,c], end=' ')\n",
        "  print('\\n')\n",
        "\n",
        "  ### DISPLAY THE ORGINAL IMAGE AND THE FEATURE MAP ###\n",
        "fig = plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(Im)\n",
        "plt.title('Original Image')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(FMap)\n",
        "plt.title('Feature Map From Filter')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filter number 11 is\n",
            "\n",
            " -28    12    33  \n",
            "\n",
            "  10    -7    -5  \n",
            "\n",
            "  34   -10    10  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADHCAYAAAAAoQhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYHUlEQVR4nO3debhddX3v8fcnOScJgTCEhBAyEBFQ4hRtDOLF27ShilSatM8jD+AQHBq0SLVOBUox5V6R2+tQ6oANbQyKIjxUK0VqRWqKCCKBIiBjbpqQxMwSZiHD9/6x1sGVvdY+Z589nrX35/U85zl7f/dvr/Vd+/z29/zWrIjAzMzKZ1SnEzAzs/q4gJuZlZQLuJlZSbmAm5mVlAu4mVlJuYCbmZWUC3iNJF0g6R+b3baGaYWko5sxLTNrDkm/lDQ/fbxU0lWdyKMnC7iksyTdJ+lZSZslXS7p4MHeExGXRMT7a5n+cNo2QtJKSS2fj9VP0lpJz0l6OvNzRBOmeVKzcqxhfkvTgcSHK+IfTuNLWzDP+ZL2Vnxu/9rs+dSQx0pJv6nI44SIeEVErCxoPyv9TPrakV/PFXBJHwP+D/AJ4CDgDcCRwE2SxlR5T1v+GNa1To2IAzI/v+pkMnX250eAd1fEFqfxVvlVxed2amWDNn03P1SRx+2tmtFwl6enCrikA4G/Ac6NiB9ExK6IWAucBswC3pm2WyrpOklXSXoSOKtyNUnSuyWtk7RD0l9nR0XZtpn/yIslPSZpu6S/ykxnnqTbJe2UtEnSl6r9Ixli2eZL2iDpk5K2ptNaJOkUSY9I+rWkC2qdr6Q3S3pY0hOSviLpP7OjfUnvlfSgpMcl/bukI4ebcy+TdJCkf0o/+42S/rek0elrL5X0H2nf2i7pmwNriJK+AcwE/jUdDX5y4G9fMf3K/ljZn6vOv4o7gfGSXpFO8xXAuDQ+MM9DJN0gaVvaL26QND3z+kpJn5H0c0lPSvqepInD/NzOkvRTSV+QtANYmi7L19P5rpN0oaRRBe13Sloj6Y1pfH36XVk8nBzS6VZbC7ol/b0z/fuckLav+n1J68M5kh4FHh1OHj1VwIE3knS672SDEfE0cCPwB5nwQuA64GDgm9n2kmYDXwHeAUwlGclPG2LeJwIvAxYAF0k6Lo3vAf4CmASckL7+Z8NcrgGHkyzfNOAi4AqSf0q/A7wJ+GtJLxlqvpImkSz7+cChwMMknx3p6wuBC4A/ASYDPwGurjPnXrUC2A0cDbwWeDMw8A9SwGeAI4DjgBnAUoCIeBfwGL8d1f9tjfOr7M+Dzb+ab/DbUfji9HnWKOBrJGu0M4HngC9VtHk38F6S781u4O9rzD/reGANMAX4NPBFku/gUcDvpvN4T0X7e0n68reAbwOvJ1n2dwJfknRAHXkU+Z/p74MHRus1fl8WpXnOHtbcIqJnfkj+WJurvHYpcFP6eClwS8XrS4Gr0scXAVdnXhsPvACcVNB2FhDA9Ez7nwOnV8njI8B3M88DOLpK25XA+9PH80m+MKPT5xPS9x6faX8XsGio+ZJ8AW7PvCZgfWZe/wa8L/P6KOBZ4MhO/41H2g+wFnga2Jn+/AtJ4Xke2C/T7gzgx1WmsQj4r4ppnpR5Ph/YUDDfbH+8JfPacOe/FLiKpCg/BvSnv2ek8aVV3jcHeLyiv16aeT47/d6MLnjvfGBv5nPbSbKmfBbwWKbd6HQaszOxs4GV6eOzgEczr70q/V5MycR2AHOqLMPKtG8P5HB3lc+38vvel5nGoN+XtP3v19O/em3b7nZgkqS+iNhd8drU9PUB6weZzhHZ1yPi2XR1bjCbM4+fBQ4AkHQs8HlgLsk/gj6SQluPHRGxJ338XPp7S+b152qcb+XyRcUq+pHAZZI+l4mJZOS/rs7cu9miiPjRwBNJ80iK4CZJA+FRpJ+5pCnAZSRrTRPS1x5vMIdsfz5ysPlXExGPSVoNXEJSFNdn3o+k8cAXgJOBQ9LwBEmjM/0yO491aR6T2LefDvhVREzPBiSdVTGNSek0sv1uHfuuEVd+B4iIwu9FFX8eEY0cVVbL92XQz76aXtuEcjvJyONPssF09emtwM2Z8GCXadwEZLft7UeyelaPy4GHgGMi4kCSVS0N/pamGGy+lcun7HOSznZ2RByc+dkvIm5rQ97dYD1JP5yU+fwOjIhXpK9fQtL/XpX+bd7Jvn2ism8+Q/JPGIB0W/bkijbZ9ww1/8F8HfhY+rvSx0g2Ex6f5j2wOSGb+4zM45nALvYdONUiuyzb02lk98HMBDYOc5rNUlQ3avm+1HVZ2J4q4BHxBMlOzC9KOllSv6RZwLXABvLb9Kq5Djg13RkyhmQVqt6iOwF4Enha0suBD9Y5nWbO9/vAq5TsBO0DziHZvj7gq8D5mR1aB0l6e5vyLr2I2AT8EPicpAMljUp3XP5u2mQCyWaXJyRNIzliKmsLyfbeAY8A4yT9oaR+4EJgbAPzH8w1JNvLry14bQLJaHZnunPyUwVt3ilpdjpavxi4LjM6H7b0vdcCn5Y0Id05+FGSTTudsI1k00/279Oy70tPFXCASHb6XAB8lqSA3UHyH3JBRDxf4zR+CZxLsjNkE8mXbSvJqGa4Pg6cCTxFstPxmjqmUY+q842I7cDbgb8l2T44G1hFunwR8V2SQzG/nR7VcD/JGozV7t3AGOABks0j15FsxoNkkPE64AmSf6bfqXjvZ4AL06MqPp4OTP4M+EeSkeczJAOSeudfVUQ8FxE/iojnCl7+O2A/klHxz4AfFLT5BskO1M0kO9z/fKh51uBckmVeA9xKsqNyeROmO2wR8SzJjtWfpn+fN7Ty+6J0I7o1IN0Es5Nkc8R/dzqfZksPydoAvCMiftzpfKycJK0k2dnXlLOUrQdH4M0i6VRJ4yXtTzKav49kz3RXkPQWSQdLGstvt4//rMNpmVmGC3j9FgK/Sn+OITkssJtWZ04A/h/J6vCpJEdSFK02m1mHeBOKmVlJeQRuZlZSDRXw9FC8hyWtlnRes5Iy6zT3bSuDujehpCcLPEJy/ZANJBe1OSMiHqj2njEaG+PYv675mQ3lNzzDC/F8wydBuW/bSFOtbzdyKv08YHVErAGQ9G2SHXtVO/k49ud4LWhglmbV3RE3D92oNu7bNqJU69uNbEKZxr7n72+g4Ip8kpZIWiVp1a66znMxa7ua+rZZp7V8J2ZELIuIuRExt7/62b1mpePBiXVaIwV8I/temGY6nbuAjFkz1dS3PTixTmukgN8JHCPpJekFnU4Hrm9OWmYd5b5tpVD3TsyI2C3pQ8C/k1xUfXl6kSezUnPftrJo6IYOEXEjya3IzLqK+7aVgc/ENDMrKRdwM7OScgE3MyspF3Azs5JyATczKykXcDOzknIBNzMrKRdwM7OScgE3MyspF3Azs5JyATczKykXcDOzknIBNzMrKRdwM7OScgE3Myuphq4HbmbWSaMPnVgY37Pj123OpDM8AjczKykXcDOzkmpoE4qktcBTwB5gd0TMbUZSw7X+wjfmYmMfL2572Jdva3E2rbf5w/nlXfXJLxa2fcviJblY/4/uanpOZtZ+zdgG/nsRsb0J0zEzs2HwTkyzAiNl7bLX9B01qzC+e83awniv7KysptECHsAPJQXwDxGxrAk5mY0UXru0Ea3RAn5iRGyUdBhwk6SHIuKWbANJS4AlAOMY3+DszMxsQENHoUTExvT3VuC7wLyCNssiYm5EzO1nbCOzM2ungbXLu9JBiNmIU/cIXNL+wKiIeCp9/Gbg4qZlNgxT52/Ixa552dWFbRf0fSIXO/yy8h+Zspe9hfH+87fkgz9qcTLdwWuXNuI1MgKfAtwq6RfAz4HvR8QPmpOWWWd57dLKoO4ReESsAV7TxFzMRoROrl2Oes1xhfG9v3iwHbPvuBeOOLgwPmpNmxMpCR9GaJY3BfiuJEi+I9/y2qWNRC7gZhW8dmll0RUFfNOPp+diE44bU9j2gLduzgcva3ZGrTXta/fnYld9YEZh2/37n8/Fnml6RmbWCb6YlZlZSbmAm5mVVFdsQjHrFtHX22OqUbfe0+kUSqW3e4uZWYm5gJuZlVRXbEI56L/zp5Fv25M/+gLga8d9Ixc7/QMfL2w7+au3N5ZYi+x58slc7Nm9PhPQrNd4BG5mVlIu4GZmJdUVm1DMuoX2RGG8OGq9ziNwM7OS6ooR+IHf+lku9ouLJxW2PWm/p3KxWWeuLmz7zFcby2sk+F8zr8/F3vXBjxa2nXz5yNxpa2bFPAI3MyspF3Azs5JyATczK6mu2AZu1i323vNAYbxvRv6SybvX5+8Fa71lyBG4pOWStkq6PxObKOkmSY+mvw9pbZpmZlaplhH4CuBLwNczsfOAmyPiUknnpc//svnptcdfzfh+Yfwv538gFxu98u5Wp9NUR/fn/8Qnvm9VYduHL291NmbWTEOOwCPiFuDXFeGFwJXp4yuBRU3Oy8zMhlDvTswpEbEpfbyZ5CawZmbWRg0fhRIRwSBn+kpaImmVpFW7KL5CoJmZDV+9R6FskTQ1IjZJmgpsrdYwIpYBywAO1ERf0sFGDEnLgbcBWyPilWlsInANMAtYC5wWEY93KscBT86dlouN91Eo7H3Tawvjo37yX23OpDPqLeDXA4uBS9Pf32taRk3ykeveUxj/6Ts+m4u9ckzxHex/c2h/LrZ/Y2mNCIeNyV9OAGD1oUfkYnt2VO7+6Cor6PId9NbdajmM8GrgduBlkjZIeh9J4f4DSY8CJ6XPzUrFO+it7IYcgUfEGVVeWtDkXMxGgpp30EtaAiwBGMf4NqRmti+fSm9WxVA76CNiWUTMjYi5/fiWdtZ+LuBm+9qS7phnqB30Zp3ma6GY7WtE7qCf8FB+Z/KeDuTRatvPPqEw/sSxxStCh/28eDoTmpXQCNe1Bfyo84pvTnDNqbNzsSUHF9/Q4fkD8yso3XAUyicOva8w/qZTfy8XO2RF997kId1BPx+YJGkD8CmSwn1turN+HXBa5zI0G1zXFnCzoXgHvZWdt4GbmZWUC7iZWUm5gJuZlVTPbQP//H++JRdbsrB4J+b/vfAfcrH3v3JJYdtjP/NoQ3ntOOXYXGzb779Q8/vfNP4rVV7x/+husOfBfP/ae+Kcwrajbr2nKfMc9eqXF8bjgeLvS+ze3fA8xywqPmpz9Wv+uTB+VP/ZhfEJ1zScSin4221mVlIu4GZmJeUCbmZWUi7gZmYl1XM7MSetGp0PLixue8K4/B2Efnn6F4sbn95AUsAofpiL7WXvsKbQqB0LfpOLHbKi4clai4xZu60w3viuxMTeex8aVvsXTn59YXztHykXG7utuPQ8v644+1PGnVIY73umt8egvb30ZmYl5gJuZlZSLuBmZiXlAm5mVlK13BNzuaStku7PxJZK2ijpnvSneA+DmZm1TC1Hoawgf+dugC9ERP4W7yPcxOX561u/fN45hW0fOfXyVqfzon7lj47ZVfVmXq3xkdf9Ry52A4e0Nwmr2e4NG1s6/b5ZMwvja8+cXhiP/MEmAIzfMIy2jxWXpHWPzSqM9xdPhr4ZxTnuXl+QTIkNOQKvcuduMzPrsEa2gX9I0r3pJhYP08zM2qzeAn458FJgDrAJ+Fy1hpKWSFoladUu8ifGmJlZfeoq4BGxJSL2RMRe4Apg3iBtl0XE3IiY28/YevM0M7MKdZ1KL2lqRGxKn/4xcP9g7Ue6l51bfP3kV286Nxfrm7OzsO2qeVc2lEPRDsvhnUrfuPcc9HAu9rUP/kVh28mXd+/Njs3KYsgCXuXO3fMlzQECWAsUX1XdbASTtBx4G7A1Il6ZxpYCfwoMXGjkgoi4sTMZ1qfv8CmF8d2btwxrOrvXPlYYn35JcbzqdBb8Ti7Wd/NdhW1H7b9/YXzvM88Mb57Dal1eQxbwKnfu/qcW5GLWbivookNkrff4TEzrWT5E1srOBdwsr6ZDZH2ElXWaC7jZvmo+RNZHWFmn9dwNHYrEruK7v8/8m9tyMY0t/qIufPV7c7F1n6w9h5ec/3Qu9sjFBxW2Pfrz+V00o3YW7+TZsuDwXOy2i/6+sG3R6fyPv654d9Dkwmj5RcSLe/okXQHc0MF0zAblAm6W0Q2HyA73aJNWq3bESZHhHm3S61zArWf5EFkrOxdw61k+RNbKzjsxzcxKyiPwYYrnqxwudud9udDMt9c+3T0FsZeeWSWHGt8PsN+cw2pPosBl879ZGP8yxzY0XTNrnEfgZmYl5RG4mZWXqtzaJ9p8O6sO8QjczKykXMDNzErKBdzMrKS8DbzLHbhydS52webjC9tecvgdrU7HzJrII3Azs5LyCNzMSqvvyBmF8Wp3E+o2HoGbmZWUC7iZWUnVclPjGST3DJxCchb3soi4TNJE4BpgFslV206LiMdbl6rVY8/2HbnYjWteVdi2aCfmwaOfLWzbN2tmLtYrq61mI0UtI/DdwMciYjbwBuAcSbOB84CbI+IY4Ob0uZmZtcmQBTwiNkXE3enjp4AHgWnAQuDKtNmVwKJWJWlmZnnDOgpF0izgtcAdwJTMnUs2k2xiKXrPEmAJwDjG15unmVlOtc12o1798sL43nsfamU6bVfzTkxJBwD/DHwkIp7MvhYRQfFVTn3jVzOzFqmpgEvqJyne34yI76ThLZKmpq9PBba2JkUzMytSy1EoIrnN1IMR8fnMS9cDi4FL09/fa0mG1nRTr6iyJvTGfOj4sbsKm649c3ouNv0SH4Vi1k61bAP/H8C7gPsk3ZPGLiAp3NdKeh+wDjitNSmamVmRIQt4RNwKVLlqOguam45Z+/gcBys7n4lpvcznOHSpPRPGFf50Gxdw61k+x8HKzlcj7EH7PbCpMH7R1tfnYhcfdmdh29e+7YFcbNsljeXVSfWc42DWaR6BW8+r9xwHSUskrZK0ahfPtyFTs325gFtPa+QcB5+kZp3mAm49q4ZzHMDnONgI5m3g1st8jkOX6t+Qv4wyJIcddRMXcOtZPsfBys4FvAft3rCxMP7TLUflg1WOQjn/iH/LxT7KCQ3lZWbD423gZmYl5QJuZlZS3oRiZl1n97r1hfHRkycXxvds29bKdFrGI3Azs5LyCNxetHPl4flg8Q3sOev+xbnYRB5pckZmNhiPwM3MSsoF3MyspFzAzcxKytvAzaxnlPVok2qGHIFLmiHpx5IekPRLSR9O40slbZR0T/pzSuvTNTOzAbWMwAduO3W3pAnAXZJuSl/7QkR8tnXpWTtNu/S2XOyPLs3f5AF8xInZSFDLTY03AZvSx09JGrjtlJmZddCwdmJW3HYK4EOS7pW0XNIhVd7ju5aYmbVAzQW84LZTlwMvBeaQjNA/V/Q+37XEzKw1ajoKpei2UxGxJfP6FcANLcnQzKxJ+mZML4zvXr+hzZk0Ry1HoRTedmrgnoGpPwbub356ZmZWTS0j8Gq3nTpD0hySO3avBc5uSYZmZlaolqNQqt126sbmp2NmZrXyqfRmZiXlAm49y2cZW9n5WijWy3yWcY8p69Em1biAW8/yWcZWdt6EYkZ9ZxmbdZoLuPW8es8y9mUirNNcwK2nVTvLOCL2RMRe4ApgXtF7fZkI6zQXcOtZPsvYyk4R0b6ZSduAdenTScD2ts28fbxcnXNkREyutbGkE4GfAPcBe9PwBcAZJJtPXjzLON3hOdi0Bvp2GT6nZvGytk9h325rAd9nxtKqiJjbkZm3kJert/XS5+Rl7TxvQjEzKykXcDOzkupkAV/WwXm3kpert/XS5+Rl7bCObQM3M7PGeBOKmVlJtb2ASzpZ0sOSVks6r93zb6b0NOutku7PxCZKuknSo+nv0p2GPchV+kq/bK3UTX27Urf29Upl6/ttLeCSRgNfBt4KzCa5q8/sdubQZCuAkyti5wE3R8QxwM3p87IZuErfbOANwDnp36kblq0lurBvV1pBd/b1SqXq++0egc8DVkfEmoh4Afg2sLDNOTRNRNwC/LoivBC4Mn18JbCorUk1QURsioi708dPAQNX6Sv9srVQV/XtSt3a1yuVre+3u4BPA9Znnm+g+y7fOSVz1t5mYEonk2lUxVX6umrZmqwX+nalru4PZej73onZQpEc4lPaw3wKrtL3orIvmzVXt/WHsvT9dhfwjcCMzPPpaaybbBm4GFL6e2uH86lL0VX66JJla5Fe6NuVurI/lKnvt7uA3wkcI+klksYApwPXtzmHVrseWJw+Xgx8r4O51KXaVfrogmVroV7o25W6rj+Ure+3/USe9AaxfweMBpZHxKfbmkATSboamE9ypbItwKeAfwGuBWaSXJ3utIio3Pkzog1ylb47KPmytVI39e1K3drXK5Wt7/tMTDOzkvJOTDOzknIBNzMrKRdwM7OScgE3MyspF3Azs5JyATczKykXcDOzknIBNzMrqf8Pjoxl59jgLIYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}